{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "门票: 18\n",
      "迪士尼: 211\n",
      "已经: 14\n",
      "一起: 38\n",
      "看到: 19\n",
      "一个: 51\n",
      "是不是: 13\n",
      "回家: 17\n",
      "必须: 13\n",
      "一次: 28\n",
      "生日: 21\n",
      "公主: 32\n",
      "知道: 22\n",
      "贝儿: 146\n",
      "终于: 33\n",
      "开园: 14\n",
      "我要: 66\n",
      "带我去: 58\n",
      "一定: 18\n",
      "真的: 31\n",
      "上海: 55\n",
      "以后: 12\n",
      "不能: 21\n",
      "呜呜: 40\n",
      "有点: 20\n",
      "哦哦哦: 15\n",
      "哇哇: 17\n",
      "好玩: 10\n",
      "巴勒斯坦: 22\n",
      "衣服: 37\n",
      "可爱: 65\n",
      "儿儿: 21\n",
      "olu: 21\n",
      "今天: 14\n",
      "第一: 23\n",
      "贝尔: 15\n",
      "喜欢: 18\n",
      "宝宝: 51\n",
      "宝贝: 12\n",
      "感觉: 12\n",
      "好看: 31\n",
      "马上: 14\n",
      "直拍: 15\n",
      "玲娜: 26\n",
      "乐园: 28\n",
      "评论: 13\n",
      "今年: 11\n",
      "中国: 10\n",
      "哇塞: 13\n",
      "女鹅: 21\n",
      "露露: 56\n",
      "啊啊啊: 10\n",
      "前排: 11\n",
      "我来: 10\n",
      "里面: 13\n",
      "不会: 15\n",
      "好好: 23\n",
      "孩子: 13\n",
      "托尼: 14\n",
      "地方: 16\n",
      "一点: 10\n",
      "朋友: 13\n",
      "啥时候: 17\n",
      "希望: 12\n",
      "朱迪: 16\n",
      "奇奇: 13\n",
      "蒂蒂: 11\n",
      "没有: 30\n",
      "闪电: 21\n",
      "尼克: 31\n",
      "以色列: 17\n",
      "去过: 35\n",
      "看看: 16\n",
      "现在: 16\n",
      "需要: 11\n",
      "声音: 10\n",
      "不要: 12\n",
      "布鲁托: 16\n",
      "达菲: 11\n",
      "玛丽: 22\n",
      "黄牛: 11\n",
      "谢帝: 16\n",
      "鞋底: 10\n",
      "飞机: 23\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'neutral.csv' # 读取CSV文件\n",
    "df = pd.read_csv(file_path, encoding='utf-8-sig')  # 编码根据文件调整\n",
    "\n",
    "# 加载停用词表\n",
    "def load_stopwords(filepath):\n",
    "    \"\"\"从文件中加载停用词表\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        stopwords = set(line.strip() for line in f)\n",
    "    return stopwords\n",
    "# 调用load_stopwords函数\n",
    "stopwords = load_stopwords('cn_stopwords.txt')\n",
    "\n",
    "# 数据清洗（清洗+分词）\n",
    "def clean_text(text, stopwords):\n",
    "    \"\"\"清洗文本，去除特殊字符、标点符号，并去除停用词\"\"\"\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text) #去除特殊字符和标点符号\n",
    "    words = jieba.lcut(cleaned_text) #使用 jieba 进行分词\n",
    "    filtered_words = [word for word in words if word not in stopwords and len(word) > 1 and not word.isdigit()] #去除停用词，并过滤掉长度为 1 的词语\n",
    "    return filtered_words #返回分词结果\n",
    "\n",
    "# 将所有文本数据拼接为一个大文本\n",
    "all_text_data = ' '.join(df.iloc[:, 1].astype(str).tolist())\n",
    "\n",
    "# 对文本进行清洗+分词处理\n",
    "cleaned_words = clean_text(all_text_data, stopwords)\n",
    "\n",
    "# 统计词频\n",
    "word_counts = Counter(cleaned_words)\n",
    "\n",
    "# 获取词频大于等于10的高频词\n",
    "top_words = [(word, count) for word, count in word_counts.items() if count >= 10]\n",
    "\n",
    "# 将结果转换为 DataFrame，并按词频降序排列\n",
    "top_words_df = pd.DataFrame(top_words, columns=['词语', '词频'])\n",
    "top_words_df = top_words_df.sort_values(by='词频', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 输出前词频大于等于10的高频词及其出现次数\n",
    "for word, count in top_words:\n",
    "    print(f'{word}: {count}')\n",
    "\n",
    "# 将结果输出至csv\n",
    "top_words_df.to_csv('disney_neutral_topWords.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
